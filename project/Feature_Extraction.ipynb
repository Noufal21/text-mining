{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature Extraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPvnPB27KRA661/uX8SYjXF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Noufal21/text-mining/blob/master/project/Feature_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ovk7ASmEsMuj",
        "outputId": "7c1710bd-0bb8-4ebf-d25c-e0703d6131a6"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/filter_train_stem_ASCII.csv.zip\"\n",
        "\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(\"done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qT7LBmW1MKM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb8db9f8-14a8-4970-8ddb-cd007cd2b754"
      },
      "source": [
        "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-17 19:35:55--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.86.126\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.86.126|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  16.4MB/s    in 98s     \n",
            "\n",
            "2020-12-17 19:37:34 (16.1 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOuUohsg7R8v",
        "outputId": "6d6a68b2-7f59-48be-9450-142e4f6c7214"
      },
      "source": [
        "!wget -c \"http://nlp.stanford.edu/data/glove.840B.300d.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-17 21:50:57--  http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.840B.300d.zip [following]\n",
            "--2020-12-17 21:50:57--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
            "--2020-12-17 21:50:58--  http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘glove.840B.300d.zip’\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  1.86MB/s    in 16m 57s \n",
            "\n",
            "2020-12-17 22:07:55 (2.04 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1Vt-uCKuZCl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59fcda88-fbbd-46ef-c976-61ef250d5dc8"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/glove.840B.300d.zip\"\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(\"done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AB7_JmD_U9d",
        "outputId": "78c83095-9f9d-429b-8226-0182774b030c"
      },
      "source": [
        "!pip install fuzzywuzzy\n",
        "!pip install distance\n",
        "import warnings\n",
        "warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.6/dist-packages (0.18.0)\n",
            "Requirement already satisfied: distance in /usr/local/lib/python3.6/dist-packages (0.1.3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH7jk0D-sQ2y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d17e8e64-5618-4cd2-974f-c8f55bb7970d"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy.attrs import ORTH, LEMMA, NORM, TAG\n",
        "from spacy.language import Language\n",
        "from spacy.tokens import Doc\n",
        "from spacy.symbols import IS_CURRENCY\n",
        "from fuzzywuzzy import fuzz\n",
        "import distance\n",
        "import gensim\n",
        "from scipy.spatial.distance import cosine, cityblock, jaccard, canberra, euclidean, minkowski, braycurtis\n",
        "from scipy.stats import skew, kurtosis\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import codecs\n",
        "from gensim.models.fasttext import FastText"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kknyxt7dt2uJ"
      },
      "source": [
        "nlp = spacy.load(\"en\", disable=['parser', 'tagger', 'ner'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbW-S5fost3Z"
      },
      "source": [
        "def tokenizeWord(question1,question2):\n",
        "  q1_token = nlp(question1)\n",
        "  q2_token = nlp(question2)\n",
        "\n",
        "\n",
        "\n",
        "  q1_token_set = set([word.lemma_ for word in q1_token if not word.is_punct and not word.is_space])\n",
        "  q2_token_set = set([word.lemma_ for word in q2_token if not word.is_punct and not word.is_space])\n",
        "  \n",
        "  q1_words = set([word.lemma_ for word in q1_token  if not word.is_space and not word.is_punct and not word.is_stop])\n",
        "  q1_stop = set([word.lemma_ for word in q1_token  if not word.is_space and not word.is_punct and  word.is_stop])\n",
        "  \n",
        "  q2_words = set([word.lemma_ for word in q2_token  if not word.is_space and not word.is_punct and not word.is_stop])\n",
        "  q2_stop = set([word.lemma_ for word in q2_token  if not word.is_space and not word.is_punct and  word.is_stop])\n",
        "  \n",
        "  common_word_count = len(q1_words.intersection(q2_words))\n",
        "  common_stop_count = len(q1_stop.intersection(q2_stop))\n",
        "  common_token_count = len(q1_token_set.intersection(q2_token_set))\n",
        "\n",
        "\n",
        "  question1 = \" \".join([word.text for word in q1_token if not word.is_punct and not word.is_space])\n",
        "  question2 = \" \".join([word.text for word in q2_token if not word.is_punct and not word.is_space])\n",
        "\n",
        "  q1_token = nlp(question1)\n",
        "  q2_token = nlp(question2)\n",
        "  return q1_token, q2_token, q1_words, q1_stop, q2_words, q2_stop, common_word_count, common_stop_count, common_token_count\n",
        "\n",
        "def get_longest_substr_ratio(q1, q2):\n",
        "    strs = list(distance.lcsubstrings(q1, q2))\n",
        "    if len(strs) == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return len(strs[0])\n",
        "\n",
        "def sent2vec(words,model):\n",
        "    M = []\n",
        "    for w in words:\n",
        "      try:\n",
        "        M.append(model[w])\n",
        "      except:\n",
        "          continue\n",
        "    M = np.array(M)\n",
        "    v = M.sum(axis=0)\n",
        "    norm = np.sqrt((v ** 2).sum())\n",
        "    if norm > 0:\n",
        "      return v/norm\n",
        "    else:\n",
        "      return None\n",
        "\n",
        "def import_embeddingModel():\n",
        "  pass\n",
        "\n",
        "def feature_extraction(question1, question2, word2vecModel, word2vecModel_norm, gloveModel,glove_norm):\n",
        "\n",
        "  q1_token, q2_token, q1_words, q1_stop, q2_words, q2_stop, common_word_count, common_stop_count, common_token_count = tokenizeWord(question1.lower(), question2.lower())\n",
        "  if len(q1_token) == 0 or len(q2_token)  == 0:\n",
        "    return [0] * 31\n",
        "  cwc_min = common_word_count / (min(len(q1_words),len(q2_words))+ 0.0001)\n",
        "  cwc_max = common_word_count / (max(len(q1_words),len(q2_words))+ 0.0001)\n",
        "\n",
        "  csc_min = common_stop_count / (min(len(q1_stop) ,len(q2_stop)) + 0.0001)\n",
        "  csc_max = common_stop_count / (max(len(q1_stop),len(q2_stop))+ 0.0001)\n",
        "\n",
        "  ctc_min = common_token_count / (min(len(q1_token) ,len(q2_token))+ 0.0001)\n",
        "  ctc_max = common_token_count / (max(len(q1_token),len(q2_token))+ 0.0001)\n",
        "\n",
        "  last_word_eq = int(q1_token[-1].text == q2_token[-1].text)\n",
        "  first_word_eq = int(q1_token[0].text == q2_token[0].text)\n",
        "  abs_len_diff  = abs(len(q1_token) - len(q2_token))\n",
        "  mean_len= (len(q1_token) + len(q2_token))/2\n",
        "\n",
        "  # Fuzz features\n",
        "\n",
        "  fuzz_qratio =  fuzz.QRatio(question1, question2)\n",
        "  fuzz_WRatio = fuzz.WRatio(question1, question2)\n",
        "  fuzz_partial_ratio = fuzz.partial_ratio(question1, question2)\n",
        "  fuzz_partial_token_set_ratio = fuzz.partial_token_set_ratio(question1,question2)\n",
        "  fuzz_partial_token_sort_ratio = fuzz.partial_token_sort_ratio(question1, question2)\n",
        "  fuzz_token_set_ratio = fuzz.token_set_ratio(question1, question2)\n",
        "  fuzz_token_sort_ratio = fuzz.token_sort_ratio(question1, question2)\n",
        "\n",
        "  longest_substr_ratio = get_longest_substr_ratio(question1,question2)/ (min(len(question1), len(question2))+ 0.0001)\n",
        "\n",
        "  q1_token = nlp(question1)\n",
        "  q2_token = nlp(question2)\n",
        "\n",
        "  question1 = [word.text for word in q1_token if not word.is_punct and not word.is_space and not word.is_stop]\n",
        "  question2 = [word.text for word in q2_token if not word.is_punct and not word.is_space and not word.is_stop]\n",
        "\n",
        "\n",
        "  # Embedding Features\n",
        "  if gloveModel == None:\n",
        "    wmd = min(word2vecModel.wmdistance(question1, question2), 10)\n",
        "    wmd_norm = min(word2vecModel_norm.wmdistance(question1, question2), 10)\n",
        "\n",
        "\n",
        "    q1vec = sent2vec(question1,word2vecModel)\n",
        "    q2vec = sent2vec(question2,word2vecModel)\n",
        "\n",
        "    if q1vec is not None and q2vec is not None:\n",
        "      cos = cosine(q1vec, q2vec)\n",
        "      city = cityblock(q1vec, q2vec)\n",
        "      jacc = jaccard(q1vec, q2vec)\n",
        "      canb = canberra(q1vec, q2vec)\n",
        "      eucl = euclidean(q1vec, q2vec)\n",
        "      mink = minkowski(q1vec, q2vec, 3)\n",
        "      bray = braycurtis(q1vec, q2vec)\n",
        "\n",
        "      q1_skew = skew(q1vec)\n",
        "      q2_skew = skew(q2vec)\n",
        "      q1_kurt = kurtosis(q1vec)\n",
        "      q2_kurt = kurtosis(q2vec)\n",
        "\n",
        "    else:\n",
        "      cos = city = jacc = canb = eucl = mink = bray = -1\n",
        "      q1_skew = q2_skew = q1_kurt = q2_kurt = 0\n",
        "\n",
        "\n",
        "  else: \n",
        "    wmd = min(gloveModel.wmdistance(question1, question2), 10)\n",
        "    wmd_norm = min(glove_norm.wmdistance(question1, question2), 10)\n",
        "    q1vec = sent2vec(question1,gloveModel)\n",
        "    q2vec = sent2vec(question2,gloveModel)\n",
        "    \n",
        "    if q1vec is not None and q2vec is not None:\n",
        "      cos = cosine(q1vec, q2vec)\n",
        "      city = cityblock(q1vec, q2vec)\n",
        "      jacc = jaccard(q1vec, q2vec)\n",
        "      canb = canberra(q1vec, q2vec)\n",
        "      eucl = euclidean(q1vec, q2vec)\n",
        "      mink = minkowski(q1vec, q2vec, 3)\n",
        "      bray = braycurtis(q1vec, q2vec)\n",
        "\n",
        "      q1_skew = skew(q1vec)\n",
        "      q2_skew = skew(q2vec)\n",
        "      q1_kurt = kurtosis(q1vec)\n",
        "      q2_kurt = kurtosis(q2vec)\n",
        "\n",
        "    else:\n",
        "      cos = city = jacc = canb = eucl = mink = bray = -1\n",
        "      q1_skew = q2_skew = q1_kurt = q2_kurt = 0\n",
        "\n",
        "  #print(cwc_min)\n",
        "  return [cwc_min,cwc_max,csc_min,csc_max,ctc_min,ctc_max,last_word_eq,first_word_eq,abs_len_diff,\n",
        "          mean_len,fuzz_qratio,fuzz_WRatio,fuzz_partial_ratio,fuzz_partial_token_set_ratio,\n",
        "          fuzz_partial_token_sort_ratio,fuzz_token_set_ratio,fuzz_token_sort_ratio,\n",
        "          longest_substr_ratio,wmd,wmd_norm,cos,city,jacc,canb,eucl,mink,bray,q1_skew,\n",
        "          q2_skew,q1_kurt,q2_kurt]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nNkBo3GuFzt"
      },
      "source": [
        "embedding_file = \"/content/GoogleNews-vectors-negative300.bin.gz\"\n",
        "w2v = gensim.models.KeyedVectors.load_word2vec_format(embedding_file, binary=True)\n",
        "w2v_norm = gensim.models.KeyedVectors.load_word2vec_format(embedding_file, binary=True)\n",
        "w2v_norm.init_sims(replace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "F9PBqUR8_9zL",
        "outputId": "382ec292-31ef-4d1c-8816-327a93ec50ab"
      },
      "source": [
        "train_df = pd.read_csv(\"/content/filter_train_stem_ASCII.csv\",index_col = False)\n",
        "train_df = train_df.dropna()\n",
        "train_df = train_df.sort_values('id').reset_index()\n",
        "train_df.head(12)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>what is the step by step guid to invest in sha...</td>\n",
              "      <td>what is the step by step guid to invest in sha...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>what is the stori of kohinoor koh i noor diamond</td>\n",
              "      <td>what would happen if the indian govern stole t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>how can i increas the speed of my internet con...</td>\n",
              "      <td>how can internet speed be increas by hack thro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>whi am i mental veri lonely how can i solv it</td>\n",
              "      <td>find the remaind when math]23^{24}[/math is di...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>which one dissolv in water quik sugar salt met...</td>\n",
              "      <td>which fish would surviv in salt water</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>astrology i am a capricorn sun cap moon and ca...</td>\n",
              "      <td>i am a tripl capricorn sun moon and ascend in ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>should i buy tiago</td>\n",
              "      <td>what keep childern activ and far from phone an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>how can i be a good geologist</td>\n",
              "      <td>what should i do to be a great geologist</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>when do you use instead of</td>\n",
              "      <td>when do you use instead of and</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>19</td>\n",
              "      <td>20</td>\n",
              "      <td>motorola company can i hack my charter motorol...</td>\n",
              "      <td>how do i hack motorola dcx3400 for free internet</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>21</td>\n",
              "      <td>22</td>\n",
              "      <td>method to find separ of slit use fresnel biprism</td>\n",
              "      <td>what are some of the thing technician can tell...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>23</td>\n",
              "      <td>24</td>\n",
              "      <td>how do i read and find my youtub comments</td>\n",
              "      <td>how can i see all my youtub comments</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index  ...  is_duplicate\n",
              "0       0  ...             0\n",
              "1       1  ...             0\n",
              "2       2  ...             0\n",
              "3       3  ...             0\n",
              "4       4  ...             0\n",
              "5       5  ...             1\n",
              "6       6  ...             0\n",
              "7       7  ...             1\n",
              "8       8  ...             0\n",
              "9       9  ...             0\n",
              "10     10  ...             0\n",
              "11     11  ...             1\n",
              "\n",
              "[12 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrlay2dFBg16"
      },
      "source": [
        "t = [feature_extraction(q1, q2, None, None, glove,glove_norm) for q1,q2 in train_df[[\"question1\",\"question2\"]].to_numpy()]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "ba_Cvke6ZfUl",
        "outputId": "3fb071cf-eba9-4282-9dab-db73c843e6df"
      },
      "source": [
        "columns = [\"cwc_min\",\"cwc_max\",\"csc_min\",\"csc_max\",\"ctc_min\",\"ctc_max\",\"last_word_eq\",\"first_word_eq\",\"abs_len_diff\",\n",
        "          \"mean_len\",\"fuzz_qratio\",\"fuzz_WRatio\",\"fuzz_partial_ratio\",'fuzz_partial_token_set_ratio',\n",
        "          \"fuzz_partial_token_sort_ratio\",\"fuzz_token_set_ratio\",\"fuzz_token_sort_ratio\",\n",
        "          \"longest_substr_ratio\",\"wmd\",\"wmd_norm\",\"cos\",\"city\",\"jacc\",\"canb\",'eucl','mink',\"bray\",\"q1_skew\",\n",
        "          \"q2_skew\",'q1_kurt',\"q2_kurt\"]\n",
        "\n",
        "token_features = pd.DataFrame(t,columns=columns)\n",
        "token_features.head(12)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cwc_min</th>\n",
              "      <th>cwc_max</th>\n",
              "      <th>csc_min</th>\n",
              "      <th>csc_max</th>\n",
              "      <th>ctc_min</th>\n",
              "      <th>ctc_max</th>\n",
              "      <th>last_word_eq</th>\n",
              "      <th>first_word_eq</th>\n",
              "      <th>abs_len_diff</th>\n",
              "      <th>mean_len</th>\n",
              "      <th>fuzz_qratio</th>\n",
              "      <th>fuzz_WRatio</th>\n",
              "      <th>fuzz_partial_ratio</th>\n",
              "      <th>fuzz_partial_token_set_ratio</th>\n",
              "      <th>fuzz_partial_token_sort_ratio</th>\n",
              "      <th>fuzz_token_set_ratio</th>\n",
              "      <th>fuzz_token_sort_ratio</th>\n",
              "      <th>longest_substr_ratio</th>\n",
              "      <th>wmd</th>\n",
              "      <th>wmd_norm</th>\n",
              "      <th>cos</th>\n",
              "      <th>city</th>\n",
              "      <th>jacc</th>\n",
              "      <th>canb</th>\n",
              "      <th>eucl</th>\n",
              "      <th>mink</th>\n",
              "      <th>bray</th>\n",
              "      <th>q1_skew</th>\n",
              "      <th>q2_skew</th>\n",
              "      <th>q1_kurt</th>\n",
              "      <th>q2_kurt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.999980</td>\n",
              "      <td>0.833319</td>\n",
              "      <td>0.999983</td>\n",
              "      <td>0.999983</td>\n",
              "      <td>0.916659</td>\n",
              "      <td>0.785709</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>13.0</td>\n",
              "      <td>92</td>\n",
              "      <td>95</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>87</td>\n",
              "      <td>100</td>\n",
              "      <td>92</td>\n",
              "      <td>0.999998</td>\n",
              "      <td>1.242895</td>\n",
              "      <td>0.182337</td>\n",
              "      <td>0.037739</td>\n",
              "      <td>3.757679</td>\n",
              "      <td>1.0</td>\n",
              "      <td>106.020161</td>\n",
              "      <td>0.274731</td>\n",
              "      <td>0.125297</td>\n",
              "      <td>0.176137</td>\n",
              "      <td>1.018397</td>\n",
              "      <td>1.196996</td>\n",
              "      <td>18.915699</td>\n",
              "      <td>18.310662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.799984</td>\n",
              "      <td>0.499994</td>\n",
              "      <td>0.599988</td>\n",
              "      <td>0.499992</td>\n",
              "      <td>0.699993</td>\n",
              "      <td>0.466664</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>12.5</td>\n",
              "      <td>67</td>\n",
              "      <td>86</td>\n",
              "      <td>71</td>\n",
              "      <td>100</td>\n",
              "      <td>73</td>\n",
              "      <td>86</td>\n",
              "      <td>65</td>\n",
              "      <td>0.583332</td>\n",
              "      <td>4.568035</td>\n",
              "      <td>0.677708</td>\n",
              "      <td>0.219182</td>\n",
              "      <td>7.389543</td>\n",
              "      <td>1.0</td>\n",
              "      <td>125.862633</td>\n",
              "      <td>0.662090</td>\n",
              "      <td>0.415619</td>\n",
              "      <td>0.307388</td>\n",
              "      <td>-0.181118</td>\n",
              "      <td>-1.012365</td>\n",
              "      <td>1.653170</td>\n",
              "      <td>7.752329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.599988</td>\n",
              "      <td>0.499992</td>\n",
              "      <td>0.399992</td>\n",
              "      <td>0.249997</td>\n",
              "      <td>0.499995</td>\n",
              "      <td>0.357140</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>12.0</td>\n",
              "      <td>39</td>\n",
              "      <td>68</td>\n",
              "      <td>38</td>\n",
              "      <td>100</td>\n",
              "      <td>70</td>\n",
              "      <td>72</td>\n",
              "      <td>64</td>\n",
              "      <td>0.188679</td>\n",
              "      <td>3.500375</td>\n",
              "      <td>0.536211</td>\n",
              "      <td>0.131042</td>\n",
              "      <td>6.912877</td>\n",
              "      <td>1.0</td>\n",
              "      <td>129.852605</td>\n",
              "      <td>0.511940</td>\n",
              "      <td>0.239491</td>\n",
              "      <td>0.296184</td>\n",
              "      <td>-0.027762</td>\n",
              "      <td>-0.532948</td>\n",
              "      <td>11.047251</td>\n",
              "      <td>5.152646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.249994</td>\n",
              "      <td>0.199996</td>\n",
              "      <td>0.111110</td>\n",
              "      <td>0.090908</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>10.0</td>\n",
              "      <td>23</td>\n",
              "      <td>28</td>\n",
              "      <td>26</td>\n",
              "      <td>35</td>\n",
              "      <td>32</td>\n",
              "      <td>30</td>\n",
              "      <td>26</td>\n",
              "      <td>0.044444</td>\n",
              "      <td>7.531046</td>\n",
              "      <td>1.188850</td>\n",
              "      <td>0.592328</td>\n",
              "      <td>15.554620</td>\n",
              "      <td>1.0</td>\n",
              "      <td>199.626794</td>\n",
              "      <td>1.088419</td>\n",
              "      <td>0.482211</td>\n",
              "      <td>0.722758</td>\n",
              "      <td>-0.683867</td>\n",
              "      <td>-0.727365</td>\n",
              "      <td>2.910043</td>\n",
              "      <td>2.424369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.499988</td>\n",
              "      <td>0.222220</td>\n",
              "      <td>0.666644</td>\n",
              "      <td>0.499988</td>\n",
              "      <td>0.571420</td>\n",
              "      <td>0.307690</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>10.0</td>\n",
              "      <td>36</td>\n",
              "      <td>86</td>\n",
              "      <td>54</td>\n",
              "      <td>100</td>\n",
              "      <td>71</td>\n",
              "      <td>68</td>\n",
              "      <td>49</td>\n",
              "      <td>0.162162</td>\n",
              "      <td>6.734644</td>\n",
              "      <td>0.907757</td>\n",
              "      <td>0.320806</td>\n",
              "      <td>10.878496</td>\n",
              "      <td>1.0</td>\n",
              "      <td>164.558107</td>\n",
              "      <td>0.801007</td>\n",
              "      <td>0.364791</td>\n",
              "      <td>0.480040</td>\n",
              "      <td>-0.130439</td>\n",
              "      <td>-0.079190</td>\n",
              "      <td>6.468015</td>\n",
              "      <td>3.385341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.666656</td>\n",
              "      <td>0.571420</td>\n",
              "      <td>0.888879</td>\n",
              "      <td>0.799992</td>\n",
              "      <td>0.705878</td>\n",
              "      <td>0.705878</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>75</td>\n",
              "      <td>79</td>\n",
              "      <td>74</td>\n",
              "      <td>100</td>\n",
              "      <td>77</td>\n",
              "      <td>83</td>\n",
              "      <td>77</td>\n",
              "      <td>0.185185</td>\n",
              "      <td>4.072657</td>\n",
              "      <td>0.609093</td>\n",
              "      <td>0.204045</td>\n",
              "      <td>8.393666</td>\n",
              "      <td>1.0</td>\n",
              "      <td>144.849014</td>\n",
              "      <td>0.638819</td>\n",
              "      <td>0.314174</td>\n",
              "      <td>0.365167</td>\n",
              "      <td>-0.831551</td>\n",
              "      <td>-0.893273</td>\n",
              "      <td>9.887077</td>\n",
              "      <td>5.285349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>7.5</td>\n",
              "      <td>18</td>\n",
              "      <td>35</td>\n",
              "      <td>39</td>\n",
              "      <td>39</td>\n",
              "      <td>39</td>\n",
              "      <td>25</td>\n",
              "      <td>23</td>\n",
              "      <td>0.111110</td>\n",
              "      <td>8.246431</td>\n",
              "      <td>1.274807</td>\n",
              "      <td>0.751018</td>\n",
              "      <td>16.119991</td>\n",
              "      <td>1.0</td>\n",
              "      <td>201.499913</td>\n",
              "      <td>1.225576</td>\n",
              "      <td>0.584168</td>\n",
              "      <td>0.812378</td>\n",
              "      <td>-0.153566</td>\n",
              "      <td>-0.930680</td>\n",
              "      <td>0.347224</td>\n",
              "      <td>13.224931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.499975</td>\n",
              "      <td>0.499975</td>\n",
              "      <td>0.599988</td>\n",
              "      <td>0.428565</td>\n",
              "      <td>0.571420</td>\n",
              "      <td>0.444440</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>8.0</td>\n",
              "      <td>61</td>\n",
              "      <td>67</td>\n",
              "      <td>66</td>\n",
              "      <td>100</td>\n",
              "      <td>69</td>\n",
              "      <td>71</td>\n",
              "      <td>61</td>\n",
              "      <td>0.344826</td>\n",
              "      <td>1.510052</td>\n",
              "      <td>0.281362</td>\n",
              "      <td>0.054163</td>\n",
              "      <td>4.542877</td>\n",
              "      <td>1.0</td>\n",
              "      <td>100.792654</td>\n",
              "      <td>0.329130</td>\n",
              "      <td>0.150444</td>\n",
              "      <td>0.183996</td>\n",
              "      <td>1.048181</td>\n",
              "      <td>1.105783</td>\n",
              "      <td>8.640427</td>\n",
              "      <td>8.392096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.999950</td>\n",
              "      <td>0.999950</td>\n",
              "      <td>0.999975</td>\n",
              "      <td>0.799984</td>\n",
              "      <td>0.999983</td>\n",
              "      <td>0.857131</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6.5</td>\n",
              "      <td>93</td>\n",
              "      <td>95</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>93</td>\n",
              "      <td>0.999996</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.171160</td>\n",
              "      <td>1.171160</td>\n",
              "      <td>16.944106</td>\n",
              "      <td>16.944106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.599988</td>\n",
              "      <td>0.499992</td>\n",
              "      <td>0.333322</td>\n",
              "      <td>0.249994</td>\n",
              "      <td>0.444440</td>\n",
              "      <td>0.444440</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>50</td>\n",
              "      <td>62</td>\n",
              "      <td>56</td>\n",
              "      <td>100</td>\n",
              "      <td>55</td>\n",
              "      <td>65</td>\n",
              "      <td>44</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>4.897002</td>\n",
              "      <td>0.721900</td>\n",
              "      <td>0.241410</td>\n",
              "      <td>9.754137</td>\n",
              "      <td>1.0</td>\n",
              "      <td>153.969825</td>\n",
              "      <td>0.694852</td>\n",
              "      <td>0.316839</td>\n",
              "      <td>0.407277</td>\n",
              "      <td>-0.367810</td>\n",
              "      <td>-0.379719</td>\n",
              "      <td>2.199797</td>\n",
              "      <td>7.115269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.499975</td>\n",
              "      <td>0.111110</td>\n",
              "      <td>0.111110</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>14.5</td>\n",
              "      <td>19</td>\n",
              "      <td>86</td>\n",
              "      <td>42</td>\n",
              "      <td>100</td>\n",
              "      <td>44</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>7.643402</td>\n",
              "      <td>1.139047</td>\n",
              "      <td>0.566844</td>\n",
              "      <td>14.810588</td>\n",
              "      <td>1.0</td>\n",
              "      <td>203.604327</td>\n",
              "      <td>1.064748</td>\n",
              "      <td>0.479725</td>\n",
              "      <td>0.753917</td>\n",
              "      <td>-0.978571</td>\n",
              "      <td>-0.484790</td>\n",
              "      <td>14.250174</td>\n",
              "      <td>7.459835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.999950</td>\n",
              "      <td>0.499988</td>\n",
              "      <td>0.599988</td>\n",
              "      <td>0.499992</td>\n",
              "      <td>0.624992</td>\n",
              "      <td>0.555549</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8.5</td>\n",
              "      <td>75</td>\n",
              "      <td>76</td>\n",
              "      <td>72</td>\n",
              "      <td>100</td>\n",
              "      <td>69</td>\n",
              "      <td>80</td>\n",
              "      <td>75</td>\n",
              "      <td>0.527776</td>\n",
              "      <td>3.742275</td>\n",
              "      <td>0.621140</td>\n",
              "      <td>0.223980</td>\n",
              "      <td>8.353479</td>\n",
              "      <td>1.0</td>\n",
              "      <td>129.862477</td>\n",
              "      <td>0.669298</td>\n",
              "      <td>0.365411</td>\n",
              "      <td>0.328143</td>\n",
              "      <td>0.258686</td>\n",
              "      <td>-0.007873</td>\n",
              "      <td>4.811245</td>\n",
              "      <td>0.287259</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     cwc_min   cwc_max   csc_min  ...   q2_skew    q1_kurt    q2_kurt\n",
              "0   0.999980  0.833319  0.999983  ...  1.196996  18.915699  18.310662\n",
              "1   0.799984  0.499994  0.599988  ... -1.012365   1.653170   7.752329\n",
              "2   0.599988  0.499992  0.399992  ... -0.532948  11.047251   5.152646\n",
              "3   0.000000  0.000000  0.249994  ... -0.727365   2.910043   2.424369\n",
              "4   0.499988  0.222220  0.666644  ... -0.079190   6.468015   3.385341\n",
              "5   0.666656  0.571420  0.888879  ... -0.893273   9.887077   5.285349\n",
              "6   0.000000  0.000000  0.000000  ... -0.930680   0.347224  13.224931\n",
              "7   0.499975  0.499975  0.599988  ...  1.105783   8.640427   8.392096\n",
              "8   0.999950  0.999950  0.999975  ...  1.171160  16.944106  16.944106\n",
              "9   0.599988  0.499992  0.333322  ... -0.379719   2.199797   7.115269\n",
              "10  0.000000  0.000000  0.499975  ... -0.484790  14.250174   7.459835\n",
              "11  0.999950  0.499988  0.599988  ... -0.007873   4.811245   0.287259\n",
              "\n",
              "[12 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYg6QREe6fJL"
      },
      "source": [
        "token_features.to_pickle(\"/content/stem_train_ASCII_features_glove\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqb8kNilt_Ga"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "word2vec embeddings start with a line with the number of lines (tokens?) and \n",
        "the number of dimensions of the file. This allows gensim to allocate memory \n",
        "accordingly for querying the model. Larger dimensions mean larger memory is \n",
        "held captive. Accordingly, this line has to be inserted into the GloVe \n",
        "embeddings file.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import smart_open\n",
        "from sys import platform\n",
        "\n",
        "import gensim\n",
        "\n",
        "\n",
        "def prepend_line(infile, outfile, line):\n",
        "\t\"\"\" \n",
        "\tFunction use to prepend lines using bash utilities in Linux. \n",
        "\t(source: http://stackoverflow.com/a/10850588/610569)\n",
        "\t\"\"\"\n",
        "\twith open(infile, 'r') as old:\n",
        "\t\twith open(outfile, 'w') as new:\n",
        "\t\t\tnew.write(str(line) + \"\\n\")\n",
        "\t\t\tshutil.copyfileobj(old, new)\n",
        "\n",
        "def prepend_slow(infile, outfile, line):\n",
        "\t\"\"\"\n",
        "\tSlower way to prepend the line by re-creating the inputfile.\n",
        "\t\"\"\"\n",
        "\twith open(infile, 'r') as fin:\n",
        "\t\twith open(outfile, 'w') as fout:\n",
        "\t\t\tfout.write(line + \"\\n\")\n",
        "\t\t\tfor line in fin:\n",
        "\t\t\t\tfout.write(line)\n",
        "\n",
        "def get_lines(glove_file_name):\n",
        "    \"\"\"Return the number of vectors and dimensions in a file in GloVe format.\"\"\"\n",
        "    with smart_open.smart_open(glove_file_name, 'r') as f:\n",
        "        num_lines = sum(1 for line in f)\n",
        "    with smart_open.smart_open(glove_file_name, 'r') as f:\n",
        "        num_dims = len(f.readline().split()) - 1\n",
        "    return num_lines, num_dims\n",
        "\t\n",
        "# Input: GloVe Model File\n",
        "# More models can be downloaded from http://nlp.stanford.edu/projects/glove/\n",
        "glove_file=\"/content/glove.840B.300d.txt\"\n",
        "\n",
        "num_lines, dims = get_lines(glove_file)\n",
        "\n",
        "# Output: Gensim Model text format.\n",
        "gensim_file='glove_model2.txt'\n",
        "gensim_first_line = \"{} {}\".format(num_lines, dims)\n",
        "\n",
        "# Prepends the line.\n",
        "if platform == \"linux\" or platform == \"linux2\":\n",
        "\tprepend_line(glove_file, gensim_file, gensim_first_line)\n",
        "else:\n",
        "\tprepend_slow(glove_file, gensim_file, gensim_first_line)\n",
        "\n",
        "# Demo: Loads the newly created glove_model.txt into gensim API.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ18L7ynzHvT"
      },
      "source": [
        "glove = gensim.models.KeyedVectors.load_word2vec_format(gensim_file,binary=False) #GloVe Model\n",
        "glove_norm = gensim.models.KeyedVectors.load_word2vec_format(gensim_file, binary=False)\n",
        "glove_norm.init_sims(replace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DND2XigWzQHl"
      },
      "source": [
        "glove.similarity('woman', 'man')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}